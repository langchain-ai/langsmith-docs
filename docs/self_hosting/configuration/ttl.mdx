import {
  CodeTabs,
  DockerBlock,
  HelmBlock,
} from "../../../src/components/InstructionsWithCode";

# TTL and Data Retention

LangSmith Self-Hosted allows enablement of automatic TTL and Data Retention of traces. This can be useful if you're complying with data privacy regulations, or if you want to have more efficient space usage and auto cleanup of your traces.
Traces will also have their data retention period automatically extended based on certain actions or run rule applications. For more details on Data Retention, take a look at the section on auto-upgrades in the [data retention guide](/administration/concepts#data-retention).

## Requirements

You can configure retention through helm or environment variable settings. There are a few options that are
configurable:

- _Enabled:_ Whether data retention is enabled or disabled. If enabled, via the UI you can your default organization and project TTL tiers to apply to traces (see [data retention guide](/administration/concepts#data-retention) for details).
- _Retention Periods:_ You can configure system-wide retention periods for shortlived and longlived traces. Once configured, you can manage the retention level at each project as well as set an organization-wide default for new projects.

<CodeTabs
  tabs={[
    HelmBlock(
      `config:
    ttl:
      enabled: true
      ttl_period_seconds:
        # -- TTL seconds - 400 day longlived and 14 day shortlived
        longlived: "34560000"
        shortlived: "1209600"
    `
    ),
    DockerBlock(
      `# In your .env file
FF_TRACE_TIERS_ENABLED=true
TRACE_TIER_TTL_DURATION_SEC_MAP='{"longlived": 34560000, "shortlived": 1209600}'
    `
    ),
  ]}
/>

## ClickHouse TTL Cleanup Job

As of version **0.11**, a cron job runs on weekends to assist in deleting expired data that may not have been cleaned up by ClickHouse's built-in TTL mechanism.

By default, it runs:
- **Saturday**: 8pm/10pm UTC
- **Sunday**: 12am/2am/4am UTC

### Disabling the Job

If you would like to disable the job entirely, you can set the following values in your `values.yaml` file:

```yaml
queue:
  extraEnv:
    - name: "ENABLE_CLICKHOUSE_TTL_CLEANUP_CRON"
      value: "false"
```

### Configuring Job Schedule

You can set the following parameters to customize the job schedule:

:::warning Important
1. If you want the job to only run on a single cron schedule, set `CLICKHOUSE_TTL_CLEANUP_CRON_WEEKEND_EVENING` and `CLICKHOUSE_TTL_CLEANUP_CRON_WEEKEND_MORNING` to the same value. We use locking to prevent job overlaps.
2. We recommend running these queries only during off-peak hours (nights and weekends) when you can handle increased system load. This job uses Delete mutations (`ALTER TABLE DELETE`) to clean up tables. 
These are expensive operations that can impact system performance, although running 1 at a time did not cause any significant spikes during our testing.
:::

```yaml
queue:
  extraEnv:
    # UTC: Sun 12am/2am/4am
    - name: "CLICKHOUSE_TTL_CLEANUP_CRON_WEEKEND_MORNING"
      value: "0 0,2,4 * * 0"
    # UTC: Sat 8pm/10pm
    - name: "CLICKHOUSE_TTL_CLEANUP_CRON_WEEKEND_EVENING"
      value: "0 20,22 * * 6"
```

### Configuring `CLICKHOUSE_TTL_CRON_MIN_EXPIRED_ROWS_PER_PART`

The job scans all parts, deleting data from parts that have a minimum number of expired rows. The value of `CLICKHOUSE_TTL_CRON_MIN_EXPIRED_ROWS_PER_PART` determines how many expired rows should be in a part before it is considered for deletion.

If this value is set too low, the job loses effectiveness, as it will scan entire parts to clear little data. If set too high, the job will miss parts that have significant expired data.

**Default value**:
```yaml
queue:
  extraEnv:
    - name: "CLICKHOUSE_TTL_CRON_MIN_EXPIRED_ROWS_PER_PART"
      value: "100000" # 100k
```

You can use this query to check the expired rows in your tables:

```sql
SELECT
    _part,
    count() AS expired_rows
FROM runs
WHERE trace_first_received_at IS NOT NULL
AND ttl_seconds IS NOT NULL
AND toDateTime(assumeNotNull(trace_first_received_at) + toIntervalSecond(assumeNotNull(ttl_seconds))) < now()
GROUP BY _part
ORDER BY expired_rows DESC
```

### Configuring `CLICKHOUSE_TTL_CRON_MAX_ACTIVE_MUTATIONS`

The delete operations can take a long time (~50 minutes for a 100GB part). To speed up the deletion process, you can increase the number of active mutations. When testing with 1 active mutation, we did not see any significant CPU, memory, or latency increases.

**Default value**:
```yaml
queue:
  extraEnv:
    - name: "CLICKHOUSE_TTL_CRON_MAX_ACTIVE_MUTATIONS"
      value: "1"
```

:::warning Performance Impact
You should only increase the number of concurrent mutations if you are comfortable with potentially slower insert and read latencies.
:::