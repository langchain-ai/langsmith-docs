---
sidebar_label: Quick Start
sidebar_position: 1
table_of_contents: true
---

import Tabs from "@theme/Tabs";
import CodeBlock from "@theme/CodeBlock";
import {
  CodeTabs,
  PythonBlock,
  TypeScriptBlock,
  typescript,
} from "@site/src/components/InstructionsWithCode";
import {
  LangChainInstallationCodeTabs,
  LangChainQuickStartCodeTabs,
  ConfigureEnvironmentCodeTabs,
  RunTreeQuickStartCodeTabs,
  ConfigureSDKEnvironmentCodeTabs,
  PythonSDKTracingCode,
  TypeScriptSDKTracingCode,
} from "@site/src/components/QuickStart";
import { ClientInstallationCodeTabs } from "@site/src/components/ClientInstallation";
import DocCardList from "@theme/DocCardList";

# Get started with LangSmith

**LangSmith** is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!

## 1. Install LangSmith

<CodeTabs
  tabs={[
    {
      value: "python",
      label: "Python",
      language: "bash",
      content: `pip install -U langsmith`,
    },
    {
      value: "typescript",
      label: "TypeScript",
      language: "bash",
      content: `yarn add langchain langsmith`,
    },
  ]}
  groupId="client-language"
/>

## 2. Create an API key

To create an API key head to the [Settings page](https://smith.langchain.com/settings). Then click **Create API Key.**

## 3. Set up your environment

<ConfigureSDKEnvironmentCodeTabs />

## 4. Log your first trace

<p>
  We provide multiple ways to log traces to LangSmith. Below, we'll highlight
  how to use <code>traceable</code>. See more on the{" "}
  <a href="./tracing/integrations">Integrations</a> page.
</p>
<CodeTabs
  tabs={[
    {
      value: "python",
      label: "Python",
      language: "python",
      content: PythonSDKTracingCode(),
    },
    {
      value: "typescript",
      label: "TypeScript",
      language: "typescript",
      content: TypeScriptSDKTracingCode(),
    },
  ]}
  groupId="client-language"
/>

- View a [sample output trace](https://smith.langchain.com/public/b37ca9b1-60cd-4a2a-817e-3c4e4443fdc0/r).
- Learn more about tracing on the [tracing page](/tracing).

## 5. Run your first evaluation

Evalution requires a system to test, [data](evaluation/faq) to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.

<CodeTabs
  tabs={[
    {
      value: "python",
      label: "Python",
      language: "python",
      content: `from langsmith import Client
from langsmith.evaluation import evaluate\n
client = Client()\n
# Define dataset: these are your test cases
dataset_name = "Sample Dataset"
dataset = client.create_dataset(dataset_name, description="A sample dataset in LangSmith.")
client.create_examples(
    inputs=[
        {"postfix": "to LangSmith"},
        {"postfix": "to Evaluations in LangSmith"},
    ],
    outputs=[
        {"output": "Welcome to LangSmith"},
        {"output": "Welcome to Evaluations in LangSmith"},
    ],
    dataset_id=dataset.id,
)\n
# Define your evaluator
def exact_match(run, example):
    return {"score": run.outputs["output"] == example.outputs["output"]}\n
experiment_results = evaluate(
    lambda input: "Welcome " + input['postfix'], # Your AI system goes here
    data=dataset_name, # The data to predict and grade over
    evaluators=[exact_match], # The evaluators to score the results
    experiment_prefix="sample-experiment", # The name of the experiment
    metadata={
      "version": "1.0.0",
      "revision_id": "beta"
    },
)
`,
    },
    typescript`
      import { Client, Run, Example } from "langsmith";
      import { evaluate } from "langsmith/evaluation";
      import { EvaluationResult } from "langsmith/evaluation";
      
      const client = new Client();
      
      // Define dataset: these are your test cases
      const datasetName = "Sample Dataset";
      const dataset = await client.createDataset(datasetName, {
        description: "A sample dataset in LangSmith.",
      });
      await client.createExamples({
        inputs: [
          { postfix: "to LangSmith" },
          { postfix: "to Evaluations in LangSmith" },
        ],
        outputs: [
          { output: "Welcome to LangSmith" },
          { output: "Welcome to Evaluations in LangSmith" },
        ],
        datasetId: dataset.id,
      });
      
      // Define your evaluator
      const exactMatch = async (
        run: Run,
        example: Example
      ): Promise<EvaluationResult> => {
        return {
          key: "exact_match",
          score: run.outputs?.output === example?.outputs?.output,
        };
      };
      
      await evaluate(
        (input: { postfix: string }) => ({ output: \`Welcome $\{input.postfix\}\` }),
        {
          data: datasetName,
          evaluators: [exactMatch],
          metadata: {
            version: "1.0.0",
            revision_id: "beta",
          },
        }
      );
    `,
  ]}
  groupId="client-language"
/>
